{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITS Data Loading\n",
    "\n",
    "In order to load fits data, let's use this custom FITSDataLoader. This code is taken from https://github.com/aritraghsh09/GaMPEN/blob/master/ggt/data/dataset.py and https://github.com/amritrau/fitsdataset/blob/master/fitsdataset/dataset.py. Please cite these two repos if you use any part of the following code.\n",
    "\n",
    "The custom FITSDataset can transform a folder of `.fits` files and an associated `.csv` into a PyTorch DataLoader. This makes it very easy for these images to be then used for training/testing any model in PyTorch.\n",
    "\n",
    "Before running this, in order to install most library dependencies that this notebook needs run the following commands in a terminal \n",
    "```bash\n",
    "pip install fitsdataset\n",
    "pip install tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FITSDataSet code creates a dataset similar to the MNIST dataset we had created in Problem #2 of PSet 10. Using this dataset, you can easily create a PyTorch dataloaders for your problem.\n",
    "\n",
    "The various options for `FITSDataSet` are summarized below:-\n",
    "\n",
    "* `data_dir` -- You need to create a directory to store all the data for your project. This argument should be the full path to that directory.\n",
    "\n",
    "    This data directory should also have a file called `info.csv` which at the very least has a column called `file_name` with the names of the various fits files, and the target column which you are trying to predict. \n",
    "\n",
    "    This data directory should also have a folder called `cutouts` containing all the images for your project.\n",
    "\n",
    "* `channels` -- The number of channels/layers in your input images. \n",
    "\n",
    "* `cutout_size` -- The height/width of your input images. Your images are assumed to be square. So, only a single integer is allowed as an input. \n",
    "\n",
    "* `label_col` -- The name of the column in `info.csv` that you are trying to predict.\n",
    "\n",
    "* `normalize` -- This can be set to True or False. Setting this to True applies an arsinh transformation on your input images. This is often helpful for training CNNs.\n",
    "\n",
    "\n",
    "* `expand_factor` -- Artificially expand the size of your dataset. If you want to use this option, you should also set pass on a set of random transformations to the `transform` argument. \n",
    "\n",
    "* `transform` -- If you want to apply additional transformations to your input image, pass them here. For example to randomly transform your image (while using `expand factor`),\n",
    "\n",
    "    ```python\n",
    "    import kornia.augmentation as K\n",
    "\n",
    "    T = nn.Sequential(\n",
    "            K.RandomHorizontalFlip(),\n",
    "            K.RandomVerticalFlip(),\n",
    "            K.RandomRotation(360),\n",
    "        )\n",
    "    ```\n",
    "\n",
    "    then you can pass the above `T` variable to the transform argument.\n",
    "\n",
    "    If you want to exploit the `transform` variable only for cropping you can also set this to\n",
    "\n",
    "    ```python\n",
    "    import kornia.augmentation as K\n",
    "\n",
    "    T = nn.Sequential(\n",
    "           K.CenterCrop(143), #this will crop the images to 143X143 pixels\n",
    "        )\n",
    "    ```\n",
    "\n",
    "    You can also combine the cropping and random transformations above if you want to.\n",
    "\n",
    "\n",
    "* `repeat_dims` -- If you want to artificially make your images have more than one channel (i.e., copy the same image to as many channels you mentioned in `channels`); set this to `True`.\n",
    "\n",
    "* `load_labels` -- This should be set to `True` unless you don't happen to have the labels for a test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "mp.set_sharing_strategy(\"file_system\")\n",
    "\n",
    "def arsinh_normalize(X):\n",
    "    \"\"\"Normalize a Torch tensor with arsinh.\"\"\"\n",
    "    return torch.log(X + (X ** 2 + 1) ** 0.5)\n",
    "\n",
    "\n",
    "def load_tensor(filename, tensors_path, as_numpy=True):\n",
    "    \"\"\"Load a Torch tensor from disk.\"\"\"\n",
    "    return torch.load(tensors_path / (filename + \".pt\")).numpy()\n",
    "\n",
    "\n",
    "class FITSDataset(Dataset):\n",
    "    \"\"\"Dataset from FITS files. Pre-caches FITS files as PyTorch tensors to\n",
    "    improve data load speed.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        channels=1,\n",
    "        cutout_size=167,\n",
    "        label_col=\"bt_g\",\n",
    "        normalize=True,\n",
    "        transform=None,\n",
    "        expand_factor=1,\n",
    "        repeat_dims=False,\n",
    "        load_labels=True,\n",
    "    ):\n",
    "\n",
    "        # Set data directories\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "        # Set cutouts shape\n",
    "        self.cutout_shape = (channels, cutout_size, cutout_size)\n",
    "\n",
    "        # Set requested transforms\n",
    "        self.normalize = normalize\n",
    "        self.transform = transform\n",
    "        self.repeat_dims = repeat_dims\n",
    "\n",
    "        # Set data expansion factor (must be an int and >= 1)\n",
    "        self.expand_factor = expand_factor\n",
    "\n",
    "        ## Read the catalog CSV file\n",
    "        catalog = self.data_dir / \"info.csv\"\n",
    "\n",
    "        # Define paths\n",
    "        self.data_info = pd.read_csv(catalog)\n",
    "        self.cutouts_path = self.data_dir / \"cutouts\"\n",
    "        self.tensors_path = self.data_dir / \"tensors\"\n",
    "        self.tensors_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Retrieve labels & filenames\n",
    "        if load_labels:\n",
    "            self.labels = np.asarray(self.data_info[label_col])\n",
    "        else:\n",
    "            # generate fake labels of appropriate shape\n",
    "            self.labels = np.ones((len(self.data_info), len(label_col)))\n",
    "\n",
    "        self.filenames = np.asarray(self.data_info[\"file_name\"])\n",
    "\n",
    "\n",
    "        # If we haven't already generated PyTorch tensor files, generate them\n",
    "        print(\"Generating PyTorch tensors from FITS files...\")\n",
    "        for filename in tqdm(self.filenames):\n",
    "            filepath = self.tensors_path / (filename + \".pt\")\n",
    "            if not filepath.is_file():\n",
    "                load_path = self.cutouts_path / filename\n",
    "                t = FITSDataset.load_fits_as_tensor(load_path)\n",
    "                torch.save(t, filepath)\n",
    "\n",
    "        # Preload the tensors\n",
    "        n = len(self.filenames)\n",
    "        print(f\"Preloading {n} tensors...\")\n",
    "        load_fn = partial(load_tensor, tensors_path=self.tensors_path)\n",
    "        with mp.Pool(mp.cpu_count()) as p:\n",
    "            # Load to NumPy, then convert to PyTorch (hack to solve system\n",
    "            # issue with multiprocessing + PyTorch tensors)\n",
    "            self.observations = list(\n",
    "                tqdm(p.imap(load_fn, self.filenames), total=n)\n",
    "            )\n",
    "        self.observations = [torch.from_numpy(x) for x in self.observations]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Magic method to index into the dataset.\"\"\"\n",
    "        if isinstance(index, slice):\n",
    "            start, stop, step = index.indices(len(self))\n",
    "            return [self[i] for i in range(start, stop, step)]\n",
    "        elif isinstance(index, int):\n",
    "            # Load image as tensor (\"wrap around\")\n",
    "            X = self.observations[index % len(self.observations)]\n",
    "\n",
    "            # Get image label (\"wrap around\"; make sure to cast to float!)\n",
    "            y = torch.tensor(self.labels[index % len(self.labels)])\n",
    "            y = y.float()\n",
    "\n",
    "            # Normalize if necessary\n",
    "            if self.normalize:\n",
    "                X = arsinh_normalize(X)  # arsinh\n",
    "\n",
    "            # Transform and reshape X\n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "\n",
    "            # Repeat dimensions along the channels axis\n",
    "            if self.repeat_dims:\n",
    "                if not self.transform:\n",
    "                    X = X.unsqueeze(0)\n",
    "                    X = X.repeat(self.cutout_shape[0], 1, 1)\n",
    "                else:\n",
    "                    X = X.repeat(1, self.cutout_shape[0], 1, 1)\n",
    "\n",
    "            X = X.view(self.cutout_shape).float()\n",
    "\n",
    "            # Return X, y\n",
    "            return X, y\n",
    "        elif isinstance(index, tuple):\n",
    "            raise NotImplementedError(\"Tuple as index\")\n",
    "        else:\n",
    "            raise TypeError(\"Invalid argument type: {}\".format(type(index)))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the effective length of the dataset.\"\"\"\n",
    "        return len(self.labels) * self.expand_factor\n",
    "\n",
    "    @staticmethod\n",
    "    def load_fits_as_tensor(filename):\n",
    "        \"\"\"Open a FITS file and convert it to a Torch tensor.\"\"\"\n",
    "        fits_np = fits.getdata(filename, memmap=False)\n",
    "        return torch.from_numpy(fits_np.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage below:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PyTorch tensors from FITS files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:00<00:00, 61057.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading 30000 tensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:16<00:00, 1848.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = FITSDataset(data_dir=\"/home/ag2422/project/git_repos/class-materials/yale-phys378/final-projects/experiments\",\n",
    "                     cutout_size=239,\n",
    "                     label_col = \"R_e\",\n",
    "                     normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now within this `dataset` variable, note that \n",
    "* `dataset[0]` will be a tuple containing the image and the label for the 0th image\n",
    "    * `dataset[0][0]` --> the image\n",
    "    * `dataset[0][1]` --> the label \n",
    "\n",
    "And so on.......\n",
    "\n",
    "To pass this dataset onto a PyTorch DataLoader you should be able to use (for example)\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "```\n",
    "\n",
    "\n",
    "## Warning\n",
    "With the line `y = y.float()` in `FITSDataSet`, the label is being made into a float. Note that you will need to alter this line of you are trying to do a classification problem, where for e.g., your classes could be labelled as `0`,`1`,`2`, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('phys378_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11e8597108caf9f4e22b25955aad526ff1c731bd77d6802ad4f39320c907efe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
